{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5acb46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import scrolledtext\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23c76d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define token types\n",
    "TOKEN_TYPES = [\n",
    "    ('IF', r'if'),\n",
    "    ('ELSE', r'else'),\n",
    "    ('WHILE', r'while'),\n",
    "    ('FOR', r'for'),\n",
    "    ('ID', r'[a-zA-Z_][a-zA-Z0-9_]*'),\n",
    "    ('INT', r'\\d+'),\n",
    "    ('FLOAT', r'\\d+\\.\\d+'),\n",
    "    ('STRING', r'\\\".*?\\\"'),\n",
    "    ('PLUS', r'\\+'),\n",
    "    ('MINUS', r'-'),\n",
    "    ('TIMES', r'\\*'),\n",
    "    ('DIVIDE', r'/'),\n",
    "    ('LPAREN', r'\\('),\n",
    "    ('RPAREN', r'\\)'),\n",
    "    ('LBRACE', r'\\{'),\n",
    "    ('RBRACE', r'\\}'),\n",
    "    ('ASSIGN', r'='),\n",
    "    ('SEMICOLON', r';'),\n",
    "    ('NEWLINE', r'\\n'),\n",
    "    ('WS', r'\\s+'),  # Include whitespace token type\n",
    "]\n",
    "\n",
    "# Concatenate all token regexes into one string for lex to use\n",
    "TOKEN_REGEX = '|'.join('(?P<%s>%s)' % pair for pair in TOKEN_TYPES)\n",
    "\n",
    "# Tokenize input string\n",
    "def tokenize(input_string):\n",
    "    return [match.group(0) for match in re.finditer(TOKEN_REGEX, input_string)]\n",
    "\n",
    "# Tokenize input file\n",
    "def tokenize_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        input_string = file.read()\n",
    "    return tokenize(input_string)\n",
    "\n",
    "def parse(tokens):\n",
    "    i = 0\n",
    "    statements = []\n",
    "    while i < len(tokens):\n",
    "        if tokens[i] == 'if':\n",
    "            parse_result, i = parse_if(tokens, i)\n",
    "            statements.append(parse_result)\n",
    "        elif tokens[i] in ['int', 'float', 'string']:\n",
    "            parse_result, i = parse_variable_declaration(tokens, i)\n",
    "            statements.append(parse_result)\n",
    "        elif tokens[i] == 'while':\n",
    "            parse_result, i = parse_while(tokens, i)\n",
    "            statements.append(parse_result)\n",
    "        elif tokens[i] in {'\\n', ' '}:\n",
    "            i += 1  # Skip whitespace characters\n",
    "            continue\n",
    "        else:\n",
    "            print(\"No parse result. Unexpected token:\", tokens[i])\n",
    "            return None\n",
    "    return statements\n",
    "\n",
    "def parse_if(tokens, i):\n",
    "    if_index = tokens.index('{', i)\n",
    "    condition_tokens = tokens[i + 2:if_index - 1]  # Adjusted range to exclude '(' and ')'\n",
    "    \n",
    "    # Find the index of '}' token for the if block\n",
    "    close_brace_index = if_index\n",
    "    brace_count = 1\n",
    "    while brace_count != 0:\n",
    "        close_brace_index += 1\n",
    "        if tokens[close_brace_index] == '{':\n",
    "            brace_count += 1\n",
    "        elif tokens[close_brace_index] == '}':\n",
    "            brace_count -= 1\n",
    "    \n",
    "    if_block_tokens = tokens[if_index + 1:close_brace_index]  # Extract tokens inside the if block\n",
    "    \n",
    "    # Find the index of '{' token for the else block\n",
    "    else_index = close_brace_index + 1\n",
    "    while tokens[else_index] != '{':\n",
    "        else_index += 1\n",
    "    \n",
    "    # Find the index of '}' token for the else block\n",
    "    close_else_brace_index = else_index\n",
    "    brace_count = 1\n",
    "    while brace_count != 0:\n",
    "        close_else_brace_index += 1\n",
    "        if tokens[close_else_brace_index] == '{':\n",
    "            brace_count += 1\n",
    "        elif tokens[close_else_brace_index] == '}':\n",
    "            brace_count -= 1\n",
    "    \n",
    "    else_block_tokens = tokens[else_index + 1:close_else_brace_index]  # Extract tokens inside the else block\n",
    "    \n",
    "    # Create parse result for if-else statement\n",
    "    parse_result = ('if_else', parse_expression(condition_tokens), parse_block(if_block_tokens), parse_block(else_block_tokens))\n",
    "    \n",
    "    return parse_result, close_else_brace_index + 1  # Move index past the closing '}'\n",
    "\n",
    "def parse_variable_declaration(tokens, i):\n",
    "    end_index = tokens.index(';', i)\n",
    "    parse_result = ('variable_declaration', tokens[i:end_index + 1])\n",
    "    return parse_result, end_index + 1  # Move index past the ';'\n",
    "\n",
    "def parse_while(tokens, i):\n",
    "    open_brace_index = i + 1\n",
    "    while tokens[open_brace_index] != '{':\n",
    "        open_brace_index += 1\n",
    "\n",
    "    close_brace_index = open_brace_index\n",
    "    brace_count = 1\n",
    "    while brace_count != 0:\n",
    "        close_brace_index += 1\n",
    "        if tokens[close_brace_index] == '{':\n",
    "            brace_count += 1\n",
    "        elif tokens[close_brace_index] == '}':\n",
    "            brace_count -= 1\n",
    "\n",
    "    condition_tokens = tokens[i + 2:open_brace_index - 1]  # Adjusted range to exclude '(' and ')'\n",
    "    block_tokens = tokens[open_brace_index + 1:close_brace_index]  # Extract tokens inside the block\n",
    "    parse_result = ('while', parse_expression(condition_tokens), parse_block(block_tokens))\n",
    "    return parse_result, close_brace_index + 1  # Move index past the closing '}'\n",
    "\n",
    "def parse_expression(expression_tokens):\n",
    "    # Assuming simple expressions like 'x > 0'\n",
    "    return ('expression', expression_tokens)\n",
    "\n",
    "def parse_block(block_tokens):\n",
    "    statements = []\n",
    "    statement = []\n",
    "    for token in block_tokens:\n",
    "        if token == ';':\n",
    "            statements.append(parse_statement(statement))\n",
    "            statement = []\n",
    "        else:\n",
    "            statement.append(token)\n",
    "    return ('block', statements)\n",
    "\n",
    "def parse_statement(statement_tokens):\n",
    "    # Assuming simple assignments like 'x = x + 1'\n",
    "    return ('statement', statement_tokens)\n",
    "\n",
    "\n",
    "class ParserApp:\n",
    "    def __init__(self, master):\n",
    "        self.master = master\n",
    "        self.master.title(\"Welcome to C-like Compiler\")\n",
    "        \n",
    "        # Welcome message and description\n",
    "        self.welcome_label = tk.Label(master, text=\"Welcome to C-like Compiler\", font=(\"Helvetica\", 16, \"bold\"))\n",
    "        self.welcome_label.pack(pady=10)\n",
    "        \n",
    "        self.description_label = tk.Label(master, text=\"This tool parses C-like code and checks for syntax errors.\", font=(\"Helvetica\", 12))\n",
    "        self.description_label.pack(pady=5)\n",
    "        \n",
    "        # Text area for code input\n",
    "        self.text_area = scrolledtext.ScrolledText(master, width=50, height=20)\n",
    "        self.text_area.pack(expand=True, fill='both')\n",
    "        \n",
    "        # Buttons for file handling and functionality\n",
    "        self.btn_open = tk.Button(master, text=\"Open File\", command=self.open_file)\n",
    "        self.btn_open.pack()\n",
    "        \n",
    "        self.btn_parse = tk.Button(master, text=\"Parse\", command=self.parse_file)\n",
    "        self.btn_parse.pack()\n",
    "        \n",
    "        self.btn_check_syntax = tk.Button(master, text=\"Check Syntax\", command=self.check_syntax)\n",
    "        self.btn_check_syntax.pack()\n",
    "        \n",
    "        # Error logger\n",
    "        self.error_logger = scrolledtext.ScrolledText(master, width=50, height=5)\n",
    "        self.error_logger.pack()\n",
    "\n",
    "    def open_file(self):\n",
    "        file_path = filedialog.askopenfilename()\n",
    "        if file_path:\n",
    "            with open(file_path, 'r') as file:\n",
    "                content = file.read()\n",
    "                self.text_area.insert('1.0', content)\n",
    "\n",
    "    def parse_file(self):\n",
    "        content = self.text_area.get('1.0', 'end-1c')\n",
    "        # Check if the user has written a test case or uploaded a file\n",
    "        if content.strip() == \"\":\n",
    "            self.error_logger.insert('end', \"Error: No input provided.\\n\")\n",
    "            return\n",
    "        tokens = tokenize(content)\n",
    "        parse_tree = parse(tokens)\n",
    "        if tokens:\n",
    "            print(\"\\nTokens:\", tokens)\n",
    "        if parse_tree:\n",
    "            print(\"\\n\\nParse tree:\", parse_tree)\n",
    "        else:\n",
    "            print(\"Parsing failed.\")\n",
    "\n",
    "    def check_syntax(self):\n",
    "        content = self.text_area.get('1.0', 'end-1c')\n",
    "        if content.strip() == \"\":\n",
    "            self.error_logger.insert('end', \"Error: No input provided.\\n\")\n",
    "            return\n",
    "        tokens = tokenize(content)\n",
    "        parse_tree = parse(tokens)\n",
    "        if not parse_tree:\n",
    "            self.error_logger.insert('end', \"Syntax Error: Parsing failed.\\n\")\n",
    "        else:\n",
    "            self.error_logger.insert('end', \"Syntax Check Passed.\\n\")\n",
    "\n",
    "def main():\n",
    "    root = tk.Tk()\n",
    "    app = ParserApp(root)\n",
    "    root.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
